{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e8a20eb",
   "metadata": {},
   "source": [
    "\n",
    "# üéß Transcrever WAV no Google Colab ‚Äî com **Quem Falou** e **Hor√°rio**\n",
    "Transcreve **WAV** com Whisper (`faster-whisper`) e gera **TXT / SRT / VTT** com:\n",
    "- R√≥tulo de quem fala (se est√©reo, separa L/R e rotula cada lado)\n",
    "- Timestamp relativo e, opcionalmente, hor√°rio real se voc√™ informar `START_CLOCK_ISO`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc67dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚¨áÔ∏è Instalar depend√™ncias\n",
    "!pip -q install faster-whisper==1.0.0 ffmpeg-python==0.2.0\n",
    "!apt -qq install -y ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c1ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚úÖ Checagens r√°pidas\n",
    "import sys, os, platform, importlib\n",
    "def ver(name):\n",
    "    try:\n",
    "        m = importlib.import_module(name); return getattr(m, \"__version__\", \"?.?.?\")\n",
    "    except Exception as e:\n",
    "        return f\"(erro: {e})\"\n",
    "print(\"Python:\", sys.version.split()[0], \"| OS:\", platform.system(), platform.release())\n",
    "print(\"faster-whisper:\", ver(\"faster_whisper\"))\n",
    "print(\"ffmpeg-python:\", ver(\"ffmpeg\"))\n",
    "!ffmpeg -version | head -n 1 || echo \"ffmpeg n√£o encontrado\"\n",
    "gpu = os.popen(\"nvidia-smi -L 2>/dev/null\").read().strip()\n",
    "print(\"\\nGPU:\", gpu if gpu else \"Sem GPU dedicada detectada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e356d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚öôÔ∏è Configura√ß√µes\n",
    "from pathlib import Path\n",
    "INPUT_DIR = Path(\"/content/entrada\")\n",
    "OUTPUT_DIR = Path(\"/content/saida\")\n",
    "INPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_SIZE = \"large-v3\"\n",
    "LANG_HINT = \"pt\"\n",
    "\n",
    "USE_VAD = True\n",
    "VAD_MIN_SILENCE_MS = 600\n",
    "VAD_SPEECH_PAD_MS  = 200\n",
    "BEAM_SIZE = 8\n",
    "BEST_OF = 5\n",
    "TEMPERATURES = [0.0, 0.2, 0.4, 0.6]\n",
    "COMPR_THR = 2.4\n",
    "LOGPROB_THR = -1.2\n",
    "NOSPEECH_THR = 0.45\n",
    "CONDITION_ON_PREV = False\n",
    "\n",
    "NORMALIZE = False\n",
    "SPLIT_STEREO = True\n",
    "\n",
    "LABEL_LEFT  = \"Agente\"\n",
    "LABEL_RIGHT = \"Cliente\"\n",
    "\n",
    "START_CLOCK_ISO = \"\"  # ex: \"2025-09-02T09:30:00-03:00\"\n",
    "\n",
    "print(\"Entrada:\", INPUT_DIR)\n",
    "print(\"Sa√≠da:  \", OUTPUT_DIR)\n",
    "print(\"Modelo:\", MODEL_SIZE, \"| Idioma:\", (LANG_HINT or \"(autodetect)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìÅ (Opcional) Montar Google Drive\n",
    "USE_DRIVE = False\n",
    "if USE_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    INPUT_DIR = Path(\"/content/drive/MyDrive/transcricoes/entrada\")\n",
    "    OUTPUT_DIR = Path(\"/content/drive/MyDrive/transcricoes/saida\")\n",
    "    INPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Drive montado.\")\n",
    "    print(\"Entrada:\", INPUT_DIR)\n",
    "    print(\"Sa√≠da:  \", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f530c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚¨ÜÔ∏è Upload de WAVs\n",
    "from google.colab import files\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "DO_UPLOAD = True\n",
    "if DO_UPLOAD:\n",
    "    print(\"Selecione um ou mais arquivos .wav...\")\n",
    "    up = files.upload()\n",
    "    for name in up.keys():\n",
    "        src = Path(\"/content\") / name\n",
    "        dst = INPUT_DIR / name\n",
    "        if src.exists():\n",
    "            shutil.move(str(src), str(dst))\n",
    "            print(\"‚úîÔ∏è Movido para:\", dst)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è N√£o encontrei ap√≥s upload:\", src)\n",
    "else:\n",
    "    print(\"Upload desativado; usando arquivos de:\", INPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üß† Fun√ß√µes\n",
    "from datetime import datetime, timedelta\n",
    "import ffmpeg\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "def fmt_rel_ts(t: float) -> str:\n",
    "    h = int(t // 3600); m = int((t % 3600) // 60); s = int(t % 60); ms = int((t - int(t)) * 1000)\n",
    "    return f\"{h:02}:{m:02}:{s:02},{ms:03}\"\n",
    "\n",
    "def fmt_wall_ts(start_clock, offset_s: float):\n",
    "    if not start_clock:\n",
    "        return None\n",
    "    ts = start_clock + timedelta(seconds=offset_s)\n",
    "    tz = ts.strftime(\"%z\"); tz_fmt = f\"{tz[:3]}:{tz[3:]}\" if tz else \"\"\n",
    "    return f\"{ts.strftime('%H:%M:%S')} {tz_fmt}\".strip()\n",
    "\n",
    "def write_outputs(base_out: Path, segments, speaker: str | None = None, start_clock=None):\n",
    "    txt_lines, srt_lines, vtt_lines = [], [], [\"WEBVTT\\n\"]\n",
    "    idx = 1\n",
    "    for seg in segments:\n",
    "        text = (seg.text or \"\").strip()\n",
    "        if not text: continue\n",
    "        rel_start = fmt_rel_ts(seg.start); rel_end = fmt_rel_ts(seg.end)\n",
    "        wall = fmt_wall_ts(start_clock, seg.start)\n",
    "        rel_hdr = rel_start[:8]; wall_hdr = f\" | {wall}\" if wall else \"\"\n",
    "        spk = (speaker or \"Speaker\").strip()\n",
    "        header_txt = f\"[{rel_hdr}{wall_hdr}] {spk}: \"\n",
    "        full_txt = f\"{header_txt}{text}\"\n",
    "        txt_lines.append(full_txt)\n",
    "        srt_text_line = f\"{spk}{' ['+wall+']' if wall else ''}: {text}\"\n",
    "        srt_lines += [str(idx), f\"{rel_start} --> {rel_end}\", srt_text_line, \"\"]\n",
    "        vtt_lines += [f\"{rel_start.replace(',', '.')} --> {rel_end.replace(',', '.')}\", srt_text_line, \"\"]\n",
    "        idx += 1\n",
    "    (base_out.with_suffix(\".txt\")).write_text(\"\\n\".join(txt_lines), encoding=\"utf-8\")\n",
    "    (base_out.with_suffix(\".srt\")).write_text(\"\\n\".join(srt_lines), encoding=\"utf-8\")\n",
    "    (base_out.with_suffix(\".vtt\")).write_text(\"\\n\".join(vtt_lines), encoding=\"utf-8\")\n",
    "\n",
    "def is_stereo(wav_path: Path) -> bool:\n",
    "    try:\n",
    "        info = ffmpeg.probe(str(wav_path))\n",
    "        for st in info.get(\"streams\", []):\n",
    "            if st.get(\"codec_type\") == \"audio\":\n",
    "                return int(st.get(\"channels\", 1)) == 2\n",
    "    except Exception:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def split_stereo(in_wav: Path, left_out: Path, right_out: Path):\n",
    "    (ffmpeg.input(str(in_wav)).output(str(left_out), ac=1, map=\"0:a:0\").overwrite_output().run(quiet=True))\n",
    "    (ffmpeg.input(str(in_wav)).output(str(right_out), ac=1, map=\"0:a:1\").overwrite_output().run(quiet=True))\n",
    "\n",
    "def loudnorm(in_wav: Path, out_wav: Path, i_lufs=\"-16\", tp_db=\"-1.5\", lra=\"11\"):\n",
    "    (ffmpeg.input(str(in_wav)).output(str(out_wav), af=f\"loudnorm=I={i_lufs}:TP={tp_db}:LRA={lra}\").overwrite_output().run(quiet=True))\n",
    "\n",
    "def build_model(model_size: str):\n",
    "    device = \"cpu\"; compute_type = \"int8\"\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda\"; compute_type = \"float16\"\n",
    "    except Exception: pass\n",
    "    print(f\"Dispositivo: {device} | compute_type: {compute_type}\")\n",
    "    return WhisperModel(model_size, device=device, compute_type=compute_type)\n",
    "\n",
    "def transcrever_um(\n",
    "    wav_path: Path, out_dir: Path, model: WhisperModel, lang_hint: str | None,\n",
    "    use_vad: bool, vad_min_silence_ms: int, vad_speech_pad_ms: int,\n",
    "    beam_size: int, best_of: int, temperatures, compression_ratio_threshold: float,\n",
    "    log_prob_threshold: float, no_speech_threshold: float, condition_on_previous_text: bool,\n",
    "    speaker_label: str | None, start_clock=None,\n",
    "):\n",
    "    base_out = out_dir / wav_path.stem\n",
    "    kwargs = dict(\n",
    "        language=None if not lang_hint else lang_hint,\n",
    "        vad_filter=use_vad, beam_size=beam_size, best_of=best_of,\n",
    "        temperature=temperatures, compression_ratio_threshold=compression_ratio_threshold,\n",
    "        log_prob_threshold=log_prob_threshold, no_speech_threshold=no_speech_threshold,\n",
    "        condition_on_previous_text=condition_on_previous_text, word_timestamps=False\n",
    "    )\n",
    "    if use_vad:\n",
    "        kwargs[\"vad_parameters\"] = dict(min_silence_duration_ms=vad_min_silence_ms, speech_pad_ms=vad_speech_pad_ms)\n",
    "    segments, info = model.transcribe(str(wav_path), **kwargs)\n",
    "    write_outputs(base_out, segments, speaker=speaker_label, start_clock=start_clock)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc83ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚ñ∂Ô∏è Processar todos os WAVs\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "start_clock = None\n",
    "if START_CLOCK_ISO.strip():\n",
    "    try:\n",
    "        start_clock = datetime.fromisoformat(START_CLOCK_ISO.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"[!] START_CLOCK_ISO inv√°lido, ignorando ({e})\")\n",
    "\n",
    "model = build_model(MODEL_SIZE)\n",
    "\n",
    "wav_files = sorted([p for p in INPUT_DIR.iterdir() if p.suffix.lower() == \".wav\"])\n",
    "if not wav_files:\n",
    "    print(\"Nenhum .wav encontrado em:\", INPUT_DIR)\n",
    "else:\n",
    "    for src in wav_files:\n",
    "        print(f\"\\n[‚Üí] Processando: {src.name}\")\n",
    "        work = src\n",
    "        tmp = []\n",
    "\n",
    "        if NORMALIZE:\n",
    "            norm = OUTPUT_DIR / f\"{src.stem}.norm.tmp.wav\"\n",
    "            try:\n",
    "                loudnorm(src, norm)\n",
    "                work = norm; tmp.append(norm)\n",
    "                print(\"   ‚Ä¢ Normalizado (loudnorm)\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ! Falha normaliza√ß√£o: {e}\")\n",
    "\n",
    "        if SPLIT_STEREO and is_stereo(work):\n",
    "            L = OUTPUT_DIR / f\"{src.stem}.L.tmp.wav\"\n",
    "            R = OUTPUT_DIR / f\"{src.stem}.R.tmp.wav\"\n",
    "            try:\n",
    "                split_stereo(work, L, R)\n",
    "                print(\"   ‚Ä¢ Est√©reo ‚Üí separando L/R\")\n",
    "                transcrever_um(L, OUTPUT_DIR, model, LANG_HINT, USE_VAD, VAD_MIN_SILENCE_MS, VAD_SPEECH_PAD_MS,\n",
    "                               BEAM_SIZE, BEST_OF, TEMPERATURES, COMPR_THR, LOGPROB_THR, NOSPEECH_THR,\n",
    "                               CONDITION_ON_PREV, LABEL_LEFT, start_clock)\n",
    "                print(\"   ‚Ä¢ Canal L transcrito\")\n",
    "                transcrever_um(R, OUTPUT_DIR, model, LANG_HINT, USE_VAD, VAD_MIN_SILENCE_MS, VAD_SPEECH_PAD_MS,\n",
    "                               BEAM_SIZE, BEST_OF, TEMPERATURES, COMPR_THR, LOGPROB_THR, NOSPEECH_THR,\n",
    "                               CONDITION_ON_PREV, LABEL_RIGHT, start_clock)\n",
    "                print(\"   ‚Ä¢ Canal R transcrito\")\n",
    "                tmp += [L, R]\n",
    "            except Exception as e:\n",
    "                print(f\"   ! Falha split est√©reo, transcrevendo mix: {e}\")\n",
    "                transcrever_um(work, OUTPUT_DIR, model, LANG_HINT, USE_VAD, VAD_MIN_SILENCE_MS, VAD_SPEECH_PAD_MS,\n",
    "                               BEAM_SIZE, BEST_OF, TEMPERATURES, COMPR_THR, LOGPROB_THR, NOSPEECH_THR,\n",
    "                               CONDITION_ON_PREV, None, start_clock)\n",
    "        else:\n",
    "            transcrever_um(work, OUTPUT_DIR, model, LANG_HINT, USE_VAD, VAD_MIN_SILENCE_MS, VAD_SPEECH_PAD_MS,\n",
    "                           BEAM_SIZE, BEST_OF, TEMPERATURES, COMPR_THR, LOGPROB_THR, NOSPEECH_THR,\n",
    "                           CONDITION_ON_PREV, None, start_clock)\n",
    "\n",
    "        for p in tmp:\n",
    "            try: p.unlink()\n",
    "            except Exception: pass\n",
    "\n",
    "        print(f\"[‚úì] Finalizado: {src.name}\")\n",
    "\n",
    "print(\"\\nConclu√≠do. Resultados em:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a1f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚¨áÔ∏è Baixar resultados\n",
    "from google.colab import files\n",
    "out_files = sorted(OUTPUT_DIR.glob(\"*\"))\n",
    "if not out_files:\n",
    "    print(\"Nada para baixar. Rode o processamento primeiro.\")\n",
    "else:\n",
    "    for f in out_files:\n",
    "        print(\"Baixando:\", f.name)\n",
    "        files.download(str(f))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}